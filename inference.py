import os
import torch
import torch.nn.functional as F
import cv2
import numpy as np
from PIL import Image
import argparse
from torchvision import transforms

from models.mobilefacenet import MobileFaceNet


class FaceComparator:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ª–∏—Ü –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, model_path, device=None):
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        self.model = self._load_model(model_path)
        self.model.eval()
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.transform = transforms.Compose([
            transforms.Resize((112, 112)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
    
    def _load_model(self, model_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        if 'config' in checkpoint:
            config = checkpoint['config']
            embedding_size = config.embedding_size
            input_size = config.input_size
        else:
            # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            embedding_size = 128
            input_size = 112
            print("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —á–µ–∫–ø–æ–∏–Ω—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = MobileFaceNet(embedding_size=embedding_size, input_size=input_size)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)  # –ï—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏
        
        model.to(self.device)
        return model
    
    def preprocess_image(self, image_path_or_array):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏"""
        if isinstance(image_path_or_array, str):
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Ñ–∞–π–ª–∞
            image = cv2.imread(image_path_or_array)
            if image is None:
                raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path_or_array}")
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            # –£–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = image_path_or_array
            if len(image.shape) == 3 and image.shape[2] == 3:
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —ç—Ç–æ BGR
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ PIL Image
        image = Image.fromarray(image)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
        image_tensor = self.transform(image)
        
        return image_tensor.unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
    
    def get_embedding(self, image):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        with torch.no_grad():
            image_tensor = self.preprocess_image(image).to(self.device)
            embedding = self.model(image_tensor)
            return embedding.cpu().numpy().flatten()
    
    def compare_faces(self, image1, image2, threshold=0.6):
        """
        –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –ª–∏—Ü
        
        Args:
            image1, image2: –ø—É—Ç–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –∏–ª–∏ numpy –º–∞—Å—Å–∏–≤—ã
            threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏
            
        Returns:
            dict: —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        embedding1 = self.get_embedding(image1)
        embedding2 = self.get_embedding(image2)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        cosine_similarity = np.dot(embedding1, embedding2) / (
            np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
        )
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –µ–≤–∫–ª–∏–¥–æ–≤–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        euclidean_distance = np.linalg.norm(embedding1 - embedding2)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        is_same_person = cosine_similarity > threshold
        
        return {
            'cosine_similarity': float(cosine_similarity),
            'euclidean_distance': float(euclidean_distance),
            'is_same_person': bool(is_same_person),
            'confidence': float(cosine_similarity) if is_same_person else float(1 - cosine_similarity),
            'threshold': threshold
        }
    
    def verify_identity(self, reference_image, test_image, threshold=0.6):
        """
        –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            reference_image: —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            test_image: –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            threshold: –ø–æ—Ä–æ–≥ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
            
        Returns:
            bool: True –µ—Å–ª–∏ —Ç–∞ –∂–µ –ª–∏—á–Ω–æ—Å—Ç—å, False –∏–Ω–∞—á–µ
        """
        result = self.compare_faces(reference_image, test_image, threshold)
        return result['is_same_person']
    
    def batch_compare(self, reference_image, test_images, threshold=0.6):
        """
        –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º —Ç–µ—Å—Ç–æ–≤—ã—Ö
        
        Args:
            reference_image: —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            test_images: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏
            
        Returns:
            list: —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        reference_embedding = self.get_embedding(reference_image)
        results = []
        
        for test_image in test_images:
            try:
                test_embedding = self.get_embedding(test_image)
                
                cosine_similarity = np.dot(reference_embedding, test_embedding) / (
                    np.linalg.norm(reference_embedding) * np.linalg.norm(test_embedding)
                )
                
                euclidean_distance = np.linalg.norm(reference_embedding - test_embedding)
                is_same_person = cosine_similarity > threshold
                
                results.append({
                    'image_path': test_image,
                    'cosine_similarity': float(cosine_similarity),
                    'euclidean_distance': float(euclidean_distance),
                    'is_same_person': bool(is_same_person),
                    'confidence': float(cosine_similarity) if is_same_person else float(1 - cosine_similarity)
                })
            except Exception as e:
                results.append({
                    'image_path': test_image,
                    'error': str(e),
                    'is_same_person': False,
                    'confidence': 0.0
                })
        
        return results
    
    def find_best_match(self, reference_image, candidate_images):
        """
        –ü–æ–∏—Å–∫ –Ω–∞–∏–ª—É—á—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å—Ä–µ–¥–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        
        Args:
            reference_image: referencer –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            candidate_images: —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            
        Returns:
            dict: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª—É—á—à–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏
        """
        results = self.batch_compare(reference_image, candidate_images)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—à–∏–±–æ–∫
        valid_results = [r for r in results if 'error' not in r]
        
        if not valid_results:
            return None
        
        # –ü–æ–∏—Å–∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
        best_match = max(valid_results, key=lambda x: x['cosine_similarity'])
        
        return best_match


def main():
    parser = argparse.ArgumentParser(description='–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü')
    parser.add_argument('--model_path', type=str, required=True,
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏ (.pth)')
    parser.add_argument('--reference', type=str, required=True,
                       help='–ü—É—Ç—å –∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é')
    parser.add_argument('--test', type=str, required=True,
                       help='–ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏')
    parser.add_argument('--threshold', type=float, default=0.6,
                       help='–ü–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.6)')
    parser.add_argument('--batch', action='store_true',
                       help='–†–µ–∂–∏–º –ø–∞–∫–µ—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (test –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π)')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
    if not os.path.exists(args.model_path):
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.model_path}")
        return
    
    if not os.path.exists(args.reference):
        print(f"–û—à–∏–±–∫–∞: —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {args.reference}")
        return
    
    if not os.path.exists(args.test):
        print(f"–û—à–∏–±–∫–∞: —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {args.test}")
        return
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–∞—Ä–∞—Ç–æ—Ä–∞
    comparator = FaceComparator(args.model_path)
    
    if args.batch and os.path.isdir(args.test):
        # –ü–∞–∫–µ—Ç–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        test_images = []
        for filename in os.listdir(args.test):
            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                test_images.append(os.path.join(args.test, filename))
        
        if not test_images:
            print("–í —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return
        
        print(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å {len(test_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏...")
        results = comparator.batch_compare(args.reference, test_images, args.threshold)
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        matches = [r for r in results if r.get('is_same_person', False)]
        
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
        print(f"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(results)}")
        print(f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(matches)}")
        print("-" * 80)
        
        for result in sorted(results, key=lambda x: x.get('cosine_similarity', 0), reverse=True):
            if 'error' in result:
                print(f"‚ùå {result['image_path']}: –û–®–ò–ë–ö–ê - {result['error']}")
            else:
                status = "‚úÖ –°–û–í–ü–ê–î–ï–ù–ò–ï" if result['is_same_person'] else "‚ùå –ù–ï –°–û–í–ü–ê–î–ê–ï–¢"
                print(f"{status} | {result['image_path']}")
                print(f"   –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: {result['cosine_similarity']:.4f}")
                print(f"   –ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {result['euclidean_distance']:.4f}")
                print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.4f}")
                print()
        
        # –õ—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        best_match = comparator.find_best_match(args.reference, test_images)
        if best_match:
            print(f"üèÜ –õ–£–ß–®–ï–ï –°–û–í–ü–ê–î–ï–ù–ò–ï:")
            print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {best_match['image_path']}")
            print(f"   –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: {best_match['cosine_similarity']:.4f}")
            print(f"   –¢–∞ –∂–µ –ª–∏—á–Ω–æ—Å—Ç—å: {'–î–∞' if best_match['is_same_person'] else '–ù–µ—Ç'}")
    
    else:
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        result = comparator.compare_faces(args.reference, args.test, args.threshold)
        
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
        print(f"–†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {args.reference}")
        print(f"–¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {args.test}")
        print("-" * 50)
        print(f"–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: {result['cosine_similarity']:.4f}")
        print(f"–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {result['euclidean_distance']:.4f}")
        print(f"–ü–æ—Ä–æ–≥: {result['threshold']}")
        print(f"–¢–∞ –∂–µ –ª–∏—á–Ω–æ—Å—Ç—å: {'–î–∞' if result['is_same_person'] else '–ù–µ—Ç'}")
        print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.4f}")
        
        if result['is_same_person']:
            print("‚úÖ –°–û–í–ü–ê–î–ï–ù–ò–ï: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –æ–¥–Ω–æ–π –ª–∏—á–Ω–æ—Å—Ç–∏")
        else:
            print("‚ùå –ù–ï –°–û–í–ü–ê–î–ê–ï–¢: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç —Ä–∞–∑–Ω—ã–º –ª–∏—á–Ω–æ—Å—Ç—è–º")


if __name__ == "__main__":
    main()